{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Lambda, merge, Dense, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential, model_from_json, load_model\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "import torch\n",
    "\n",
    "%run data_loader.ipynb\n",
    "#%run encoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared_data = prepare_data(X)\n",
    "train_prepared_data = np.array(train_prepared_data)\n",
    "input_x  = train_prepared_data/np.mean(train_prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Genuine','Forged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              #  loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46061/46061 [==============================] - 17s 366us/sample - loss: 0.1432 - acc: 0.9455\n",
      "Epoch 2/100\n",
      "46061/46061 [==============================] - 17s 366us/sample - loss: 0.1103 - acc: 0.9582\n",
      "Epoch 3/100\n",
      "46061/46061 [==============================] - 16s 348us/sample - loss: 0.1036 - acc: 0.9615\n",
      "Epoch 4/100\n",
      "46061/46061 [==============================] - 16s 345us/sample - loss: 0.0931 - acc: 0.9655\n",
      "Epoch 5/100\n",
      "46061/46061 [==============================] - 18s 395us/sample - loss: 0.0886 - acc: 0.9685 - loss: 0.0886 - acc: 0.9\n",
      "Epoch 6/100\n",
      "46061/46061 [==============================] - 17s 368us/sample - loss: 0.0814 - acc: 0.9703 - loss: 0.0814 - a\n",
      "Epoch 7/100\n",
      "46061/46061 [==============================] - 16s 356us/sample - loss: 0.0759 - acc: 0.9721\n",
      "Epoch 8/100\n",
      "46061/46061 [==============================] - 17s 375us/sample - loss: 0.0667 - acc: 0.9757\n",
      "Epoch 9/100\n",
      "46061/46061 [==============================] - 17s 372us/sample - loss: 0.0660 - acc: 0.9757 - loss: 0.0\n",
      "Epoch 10/100\n",
      "46061/46061 [==============================] - 16s 357us/sample - loss: 0.0638 - acc: 0.9767\n",
      "Epoch 11/100\n",
      "46061/46061 [==============================] - 16s 353us/sample - loss: 0.0631 - acc: 0.9776\n",
      "Epoch 12/100\n",
      "46061/46061 [==============================] - 16s 356us/sample - loss: 0.0560 - acc: 0.9810\n",
      "Epoch 13/100\n",
      "46061/46061 [==============================] - 16s 357us/sample - loss: 0.0567 - acc: 0.9797\n",
      "Epoch 14/100\n",
      "46061/46061 [==============================] - 17s 363us/sample - loss: 0.0477 - acc: 0.9835\n",
      "Epoch 15/100\n",
      "46061/46061 [==============================] - 18s 381us/sample - loss: 0.0507 - acc: 0.9820 - loss: 0.0507 - acc: 0 - ETA: 0s - loss: 0.0507 - acc: 0.9 - ETA: 0s - loss: 0.050\n",
      "Epoch 16/100\n",
      "46061/46061 [==============================] - ETA: 0s - loss: 0.0411 - acc: 0.985 - 17s 368us/sample - loss: 0.0411 - acc: 0.9857\n",
      "Epoch 17/100\n",
      "46061/46061 [==============================] - 19s 417us/sample - loss: 0.0503 - acc: 0.9827 - loss: 0.0498 - acc: - ETA: 4s - loss: 0.0497 - - ETA: 4s - loss: 0.0495 - acc - ETA: 3s - loss: 0.0495 - ac\n",
      "Epoch 18/100\n",
      "46061/46061 [==============================] - 21s 450us/sample - loss: 0.0405 - acc: 0.9857 - loss: 0.0397 - acc: 0.985 - ETA: 1s - - ETA: 0s - loss: 0.0404 - acc:\n",
      "Epoch 19/100\n",
      "46061/46061 [==============================] - 22s 478us/sample - loss: 0.0420 - acc: 0.9859 - loss: 0.0\n",
      "Epoch 20/100\n",
      "46061/46061 [==============================] - 18s 382us/sample - loss: 0.0394 - acc: 0.9869\n",
      "Epoch 21/100\n",
      "46061/46061 [==============================] - 16s 338us/sample - loss: 0.0421 - acc: 0.9857\n",
      "Epoch 22/100\n",
      "46061/46061 [==============================] - 15s 322us/sample - loss: 0.0350 - acc: 0.9887\n",
      "Epoch 23/100\n",
      "46061/46061 [==============================] - 15s 332us/sample - loss: 0.0282 - acc: 0.9902\n",
      "Epoch 24/100\n",
      "46061/46061 [==============================] - 15s 324us/sample - loss: 0.0420 - acc: 0.9857 - loss: 0.0421 - acc: 0.985\n",
      "Epoch 25/100\n",
      "46061/46061 [==============================] - 15s 323us/sample - loss: 0.0320 - acc: 0.9899\n",
      "Epoch 26/100\n",
      "46061/46061 [==============================] - 15s 326us/sample - loss: 0.0297 - acc: 0.9904\n",
      "Epoch 27/100\n",
      "46061/46061 [==============================] - 15s 326us/sample - loss: 0.0331 - acc: 0.9891\n",
      "Epoch 28/100\n",
      "46061/46061 [==============================] - 15s 333us/sample - loss: 0.0267 - acc: 0.9916\n",
      "Epoch 29/100\n",
      "46061/46061 [==============================] - 15s 326us/sample - loss: 0.0288 - acc: 0.9905\n",
      "Epoch 30/100\n",
      "46061/46061 [==============================] - 15s 330us/sample - loss: 0.0249 - acc: 0.9918 - loss: 0.0251 - acc\n",
      "Epoch 31/100\n",
      "46061/46061 [==============================] - 15s 325us/sample - loss: 0.0342 - acc: 0.9893\n",
      "Epoch 32/100\n",
      "46061/46061 [==============================] - 15s 328us/sample - loss: 0.0147 - acc: 0.9958\n",
      "Epoch 33/100\n",
      "46061/46061 [==============================] - 15s 324us/sample - loss: 0.0374 - acc: 0.9885\n",
      "Epoch 34/100\n",
      "46061/46061 [==============================] - 15s 326us/sample - loss: 0.0165 - acc: 0.9951\n",
      "Epoch 35/100\n",
      "46061/46061 [==============================] - 15s 326us/sample - loss: 0.0372 - acc: 0.9885\n",
      "Epoch 36/100\n",
      "46061/46061 [==============================] - 15s 329us/sample - loss: 0.0199 - acc: 0.9941\n",
      "Epoch 37/100\n",
      "46061/46061 [==============================] - 15s 330us/sample - loss: 0.0286 - acc: 0.9907\n",
      "Epoch 38/100\n",
      "46061/46061 [==============================] - 15s 328us/sample - loss: 0.0115 - acc: 0.9965\n",
      "Epoch 39/100\n",
      "46061/46061 [==============================] - 15s 327us/sample - loss: 0.0342 - acc: 0.9899\n",
      "Epoch 40/100\n",
      "46061/46061 [==============================] - 15s 334us/sample - loss: 0.0283 - acc: 0.9912\n",
      "Epoch 41/100\n",
      "46061/46061 [==============================] - 15s 325us/sample - loss: 0.0208 - acc: 0.9933\n",
      "Epoch 42/100\n",
      "46061/46061 [==============================] - 15s 327us/sample - loss: 0.0198 - acc: 0.9942\n",
      "Epoch 43/100\n",
      "46061/46061 [==============================] - 16s 351us/sample - loss: 0.0271 - acc: 0.9920\n",
      "Epoch 44/100\n",
      "46061/46061 [==============================] - 15s 330us/sample - loss: 0.0179 - acc: 0.9945\n",
      "Epoch 45/100\n",
      "46061/46061 [==============================] - 15s 331us/sample - loss: 0.0183 - acc: 0.9946\n",
      "Epoch 46/100\n",
      "46061/46061 [==============================] - 15s 329us/sample - loss: 0.0264 - acc: 0.9917\n",
      "Epoch 47/100\n",
      "46061/46061 [==============================] - 15s 329us/sample - loss: 0.0192 - acc: 0.9939\n",
      "Epoch 48/100\n",
      "46061/46061 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.994 - 15s 327us/sample - loss: 0.0157 - acc: 0.9948\n",
      "Epoch 49/100\n",
      "46061/46061 [==============================] - 15s 329us/sample - loss: 0.0236 - acc: 0.9925 - loss: 0.0237 - acc: 0.99\n",
      "Epoch 50/100\n",
      "46061/46061 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.995 - 15s 332us/sample - loss: 0.0144 - acc: 0.9952\n",
      "Epoch 51/100\n",
      "46061/46061 [==============================] - 15s 330us/sample - loss: 0.0198 - acc: 0.9942\n",
      "Epoch 52/100\n",
      "46061/46061 [==============================] - 15s 329us/sample - loss: 0.0214 - acc: 0.9933\n",
      "Epoch 53/100\n",
      "46061/46061 [==============================] - 15s 329us/sample - loss: 0.0205 - acc: 0.9944\n",
      "Epoch 54/100\n",
      "46061/46061 [==============================] - 15s 329us/sample - loss: 0.0172 - acc: 0.9945\n",
      "Epoch 55/100\n",
      "46061/46061 [==============================] - 15s 333us/sample - loss: 0.0171 - acc: 0.9950\n",
      "Epoch 56/100\n",
      "46061/46061 [==============================] - 15s 330us/sample - loss: 0.0131 - acc: 0.9962\n",
      "Epoch 57/100\n",
      "46061/46061 [==============================] - 15s 332us/sample - loss: 0.0232 - acc: 0.9934\n",
      "Epoch 58/100\n",
      "46061/46061 [==============================] - 15s 331us/sample - loss: 0.0211 - acc: 0.9940\n",
      "Epoch 59/100\n",
      "46061/46061 [==============================] - 15s 332us/sample - loss: 0.0174 - acc: 0.9947\n",
      "Epoch 60/100\n",
      "46061/46061 [==============================] - 15s 331us/sample - loss: 0.0103 - acc: 0.9972 - loss: 0.0106 - acc\n",
      "Epoch 61/100\n",
      "46061/46061 [==============================] - 15s 330us/sample - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 62/100\n",
      "46061/46061 [==============================] - 15s 331us/sample - loss: 0.0136 - acc: 0.9977\n",
      "Epoch 63/100\n",
      "46061/46061 [==============================] - 15s 332us/sample - loss: 0.0418 - acc: 0.9894\n",
      "Epoch 64/100\n",
      "46061/46061 [==============================] - 15s 333us/sample - loss: 0.0054 - acc: 0.9989\n",
      "Epoch 65/100\n",
      "46061/46061 [==============================] - 15s 335us/sample - loss: 0.0217 - acc: 0.9936\n",
      "Epoch 66/100\n",
      "46061/46061 [==============================] - 15s 331us/sample - loss: 0.0173 - acc: 0.9950\n",
      "Epoch 67/100\n",
      "46061/46061 [==============================] - 15s 333us/sample - loss: 0.0150 - acc: 0.9960\n",
      "Epoch 68/100\n",
      "46061/46061 [==============================] - 15s 333us/sample - loss: 0.0206 - acc: 0.9941\n",
      "Epoch 69/100\n",
      "46061/46061 [==============================] - ETA: 0s - loss: 0.0121 - acc: 0.996 - 15s 330us/sample - loss: 0.0121 - acc: 0.9965\n",
      "Epoch 70/100\n",
      "46061/46061 [==============================] - 16s 338us/sample - loss: 0.0090 - acc: 0.9974\n",
      "Epoch 71/100\n",
      "46061/46061 [==============================] - 15s 333us/sample - loss: 0.0190 - acc: 0.9947\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46061/46061 [==============================] - 14s 311us/sample - loss: 0.0047 - acc: 0.9987\n",
      "Epoch 73/100\n",
      "46061/46061 [==============================] - 15s 315us/sample - loss: 0.0266 - acc: 0.9925\n",
      "Epoch 74/100\n",
      "46061/46061 [==============================] - 14s 312us/sample - loss: 0.0119 - acc: 0.9967\n",
      "Epoch 75/100\n",
      "46061/46061 [==============================] - 14s 314us/sample - loss: 0.0133 - acc: 0.9962\n",
      "Epoch 76/100\n",
      "46061/46061 [==============================] - 14s 314us/sample - loss: 0.0154 - acc: 0.9955\n",
      "Epoch 77/100\n",
      "46061/46061 [==============================] - 14s 312us/sample - loss: 0.0093 - acc: 0.9974\n",
      "Epoch 78/100\n",
      "46061/46061 [==============================] - 14s 313us/sample - loss: 0.0238 - acc: 0.9932\n",
      "Epoch 79/100\n",
      "46061/46061 [==============================] - 14s 314us/sample - loss: 0.0061 - acc: 0.9984 - loss: 0.0055 - acc:\n",
      "Epoch 80/100\n",
      "46061/46061 [==============================] - 15s 318us/sample - loss: 0.0194 - acc: 0.9949\n",
      "Epoch 81/100\n",
      "46061/46061 [==============================] - 17s 366us/sample - loss: 0.0090 - acc: 0.9974 - loss: 0.0093 - acc: 0.9 - ETA: 0s - loss: \n",
      "Epoch 82/100\n",
      "46061/46061 [==============================] - 15s 326us/sample - loss: 0.0130 - acc: 0.9967\n",
      "Epoch 83/100\n",
      "46061/46061 [==============================] - 15s 323us/sample - loss: 0.0186 - acc: 0.9944\n",
      "Epoch 84/100\n",
      "46061/46061 [==============================] - 15s 317us/sample - loss: 0.0162 - acc: 0.9954\n",
      "Epoch 85/100\n",
      "46061/46061 [==============================] - 15s 317us/sample - loss: 0.0048 - acc: 0.9988 - \n",
      "Epoch 86/100\n",
      "46061/46061 [==============================] - 15s 317us/sample - loss: 0.0228 - acc: 0.9946 - loss: 0.0222 \n",
      "Epoch 87/100\n",
      "46061/46061 [==============================] - 16s 357us/sample - loss: 0.0080 - acc: 0.9977\n",
      "Epoch 88/100\n",
      "46061/46061 [==============================] - 20s 436us/sample - loss: 0.0131 - acc: 0.9963 3s - loss: 0.0137 - acc: - ETA: 3s - loss:  -\n",
      "Epoch 89/100\n",
      "46061/46061 [==============================] - ETA: 0s - loss: 0.0171 - acc: 0.9955  ETA: 12s - loss: 0. - ETA: 11s -  - ETA: 11s - ETA: 2s - loss: 0.0173 - acc: 0.9 - ETA: 2s - loss: 0.0174 - acc:  - ETA: 2s - loss: 0.0173 - acc: 0.9 - ETA: 2s - loss: 0.0173 - acc: - ETA: 2s - loss: 0.0172 - acc: 0.99 - ETA: - 22s 469us/sample - loss: 0.0171 - acc: 0.9955\n",
      "Epoch 90/100\n",
      "46061/46061 [==============================] - 25s 550us/sample - loss: 0.0039 - acc: 0.9987s - lo - E - E - ETA: 11s - loss: 0.0042 - a - ETA: 11s - loss: 0. - ETA: 10s - loss: 0.0 - ETA: 9s - loss: 0.0043 - acc:  - ETA: 9s - loss: - ETA: 8s - loss: 0.0044  - ETA: 7s - loss: 0.0043 - acc - ETA: 7s - loss: 0.0043 - acc - ETA: 7s - loss: 0.0043 - acc: 0.9 - ETA: 6s - loss: 0.0043 - acc: 0.9 - ETA: 6s - loss: 0.0043 - acc: 0 - ETA: 6s - loss: 0.0042 - acc: 0.9 - ETA: 6s - loss: 0.0042 - acc: 0.998  - ETA:  - ETA: 2s - loss: 0.0041 - acc: 0. - ETA: 2s - loss: 0.0041 - acc - ET - ETA: 0s - loss: 0.0039 - a\n",
      "Epoch 91/100\n",
      "46061/46061 [==============================] - 22s 486us/sample - loss: 8.2864e-04 - acc: 0.9999loss: 0.0011 - a - ETA: 28s - loss: 9.8542e-04 - acc:  - - ET\n",
      "Epoch 92/100\n",
      "46061/46061 [==============================] - 17s 376us/sample - loss: 4.0647e-04 - acc: 1.0000 - loss: 4.0933e-04 - acc: 1.0 - ETA: 0s - loss: 4.0645e-04 - acc: 1 - ETA: 0s - loss: 4.0728e-04 - acc: 1.0\n",
      "Epoch 93/100\n",
      "46061/46061 [==============================] - 22s 472us/sample - loss: 0.0441 - acc: 0.9911s - loss  - ETA: 1s - loss: 0.0462 - - ETA: 0s - loss: 0.0450 - acc:\n",
      "Epoch 94/100\n",
      "46061/46061 [==============================] - 24s 521us/sample - loss: 0.0013 - acc: 0.9999s - loss: 0.0022 - acc: 0.99 - - ETA: 17s - loss: 0. - ETA: 17s - loss: 0.0020 - a - ETA: 17s - loss: 0. - - ETA: 16s - loss: 0.0016 - acc:  - ETA: 16s - loss: 0.0016 - - ETA: 16s  - ETA:  - ETA: 13s  - ETA: 13s - loss: 0.00 - ETA: 6s - loss: 0.00 - ETA: 5s  - ETA: 2s - loss: 0.0013 - acc: 0.9 \n",
      "Epoch 95/100\n",
      "46061/46061 [==============================] - 23s 491us/sample - loss: 5.4813e-04 - acc: 1.0000s - loss:  - ETA - ETA: 6s - loss: 5.5164e-04 - acc: 1.0 - ETA: 6s - loss: 5 - ETA: 5s - loss: 5.4111e-04 - ac - ETA:  - ETA: 3s - loss: 5.5908e-04 - ac\n",
      "Epoch 96/100\n",
      "46061/46061 [==============================] - 20s 436us/sample - loss: 3.4976e-04 - acc: 1.0000 - loss: 3.6627e-04 - acc: 1.000 - ETA: 8s - loss: 3.6653e-04 - acc: 1. - ETA: 8s - loss: 3.7093e-04 - a -  - ETA: 6s - \n",
      "Epoch 97/100\n",
      "46061/46061 [==============================] - 19s 411us/sample - loss: 2.4654e-04 - acc: 1.0000 - loss: 2.4683e-04 - acc: 1.00\n",
      "Epoch 98/100\n",
      "46061/46061 [==============================] - 21s 445us/sample - loss: 0.0493 - acc: 0.9899 - loss:\n",
      "Epoch 99/100\n",
      "46061/46061 [==============================] - 20s 438us/sample - loss: 0.0028 - acc: 0.9994 - l - ETA: 0s - loss: 0.0029 - acc: 0\n",
      "Epoch 100/100\n",
      "46061/46061 [==============================] - 19s 408us/sample - loss: 0.0099 - acc: 0.9977: 10s - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b8b2877f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.fit(input_x, T, epochs=500, batch_size=50)\n",
    "clf.fit(input_x, T, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23205/23205 [==============================] - 2s 74us/sample - loss: 0.0316 - acc: 0.9922\n",
      "Test accuracy: 0.99215686\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "test_data = pd.read_csv(\"data/validation_data.csv\")\n",
    "test_data = test_data.iloc[np.random.permutation(len(test_data))]\n",
    "#test_data = test_data[:20]\n",
    "test_X = test_data.iloc[:,:-1].values\n",
    "test_T = test_data.iloc[:,-1].values\n",
    "\n",
    "test_X[:,0] = 'data/train/'+test_X[:,0]\n",
    "test_X[:,1] = 'data/train/'+test_X[:,1]\n",
    "\n",
    "test_prepared_data = prepare_data(test_X)\n",
    "\n",
    "test_prepared_data = np.array(test_prepared_data)\n",
    "test_prepared_data  = test_prepared_data/np.mean(test_prepared_data)\n",
    "\n",
    "test_loss, test_acc = clf.evaluate(test_prepared_data, test_T)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 0 0]\n",
      "[1 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_predictions = clf.predict(test_prepared_data)\n",
    "print(test_T)\n",
    "\n",
    "prediction = []\n",
    "for i in range(test_predictions.shape[0]):\n",
    "    prediction.append(np.argmax(test_predictions[i]))\n",
    "    \n",
    "print(np.array(prediction) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = clf.to_json()\n",
    "with open(\"checkpoint/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "clf.save_weights(\"checkpoint/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "clf.save('checkpoint/trained_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
